---
stepsCompleted: [1, 2, 3, 4]
status: 'complete'
completedAt: '2026-02-22'
inputDocuments:
  - '_bmad-output/planning-artifacts/prd.md'
  - '_bmad-output/planning-artifacts/architecture.md'
  - '_bmad-output/planning-artifacts/ux-design-specification/'
  - '_bmad-output/planning-artifacts/confidence-algo.md'
  - 'new-formula.md'
  - '_bmad-output/design-thinking-2026-02-20.md'
---

# big-ocean - Epic Breakdown

## Overview

This document provides the complete epic and story breakdown for big-ocean, decomposing the requirements from the PRD, UX Design, Architecture, and supplemental design documents into implementable stories. The architecture represents a two-tier redesign (conversanalyzer + finanalyzer) replacing the original LangGraph-based pipeline.

## Requirements Inventory

### Functional Requirements

**Assessment Core:**
- FR1: Users can start a conversational personality assessment with Nerin AI agent
- FR2: Nerin conducts a ~30-message conversational dialogue exploring Big Five personality dimensions
- FR3: System analyzes user messages to extract Big Five facet evidence with scores (0-20) and confidence (0-1)
- FR4: System computes facet scores using context-weighted means with redundancy control (√Σc_i per domain)
- FR5: System computes facet confidence using exponential saturation formula (C_max(1 - e^{-kW}))
- FR5.1: System computes facet signal power as cross-context entropy × volume saturation
- FR6: System generates a 5-letter OCEAN code (L/M/H per trait) from aggregated facet scores
- FR7: System assigns a personality archetype name based on OCEAN code and trait analysis
- FR8: Users can view their personality profile (private, full detail)
- FR9: Users can generate a shareable public archetype link (OCEAN code + archetype + essence only)
- FR10: System tracks assessment precision as message-count progress (MESSAGE_THRESHOLD=30) for MVP

**Context Tagging & Steering:**
- FR11: Conversanalyzer tags each evidence record with `domain` (hard enum: work/relationships/family/leisure/solo/other) and `rawDomain` (free-text LLM label)
- FR12: When a message spans domains, analyzer generates separate evidence records with same quote but different domain tags
- FR13: Steering selects target facet using FacetPriority formula (confidence gap + signal power gap)
- FR14: Steering selects target context using ContextPriority formula (need per context + zero-evidence boost)
- FR15: Steering hint includes a conversational bridge referencing something the user already said

**Two-Tier Analysis:**
- FR16: Conversanalyzer (Haiku) runs synchronously on every message, extracting basic facet signals + domain tags
- FR17: Conversation evidence is disposable — exists only for steering, capped at 3 records per message
- FR17.1: Finanalyzer (Sonnet/Opus) runs once at finalization, re-analyzing ALL messages with complete context
- FR18: Finalization evidence is the single source of truth for portrait and results
- FR19: Three-tier finalization idempotency: check existing result → check existing evidence → full LLM run

**Authentication & Session:**
- FR20: Users can sign up and log in (email/password via Better Auth)
- FR21: Anonymous users can start an assessment with httpOnly cookie-based session
- FR22: Anonymous sessions transition to authenticated users with token rotation
- FR23: One active session per user (lifetime), enforced by partial unique index
- FR24: Advisory lock (pg_try_advisory_lock) prevents concurrent messages on same session
- FR25: Session re-entry routing: active → finalizing → completed

**Results & Portrait:**
- FR26: Frontend triggers finalization via POST /generate-results (auth-required)
- FR27: Portrait generated by dedicated LLM call using context-grouped finalization evidence
- FR28: Assessment results stored in assessment_results table (JSONB facets/traits/domainCoverage + TEXT portrait)
- FR29: Portrait receives evidence grouped by domain with available narrative moves pre-computed

**Cost & Rate Limiting:**
- FR30: System tracks daily LLM cost per user with $75 daily budget limit
- FR31: Rate limiting: 1 new assessment per user per day (unlimited message resumption)
- FR32: Budget check runs before each message; throws BudgetPausedError if exceeded

**Infrastructure:**
- FR33: Health check endpoint (GET /health)
- FR34: Effect/Platform HTTP contracts shared between frontend and backend
- FR35: Docker Compose development environment

### NonFunctional Requirements

**Performance:**
- NFR1: Nerin response streaming with < 2 second perceived latency
- NFR2: Conversanalyzer (Haiku) completes in < 1 second synchronously
- NFR3: Assessment supports 30+ message sessions without degradation
- NFR4: Finalization completes within acceptable time for user-facing wait screen

**Security:**
- NFR5: TLS 1.3 encryption in transit
- NFR6: Better Auth password security (12+ char, compromised credential checks)
- NFR7: Default-private profiles (zero public discovery, explicit sharing only)
- NFR8: PostgreSQL RLS for data access control
- NFR9: httpOnly cookies for session tokens

**Reliability:**
- NFR10: Session state persists on server — users can pause and resume
- NFR11: Advisory lock prevents race conditions on concurrent messages
- NFR12: Three-tier finalization idempotency prevents duplicate processing
- NFR13: Redis cost tracking with atomic operations and TTL-based daily reset

**Scalability:**
- NFR14: Haiku-based conversation analysis keeps per-message LLM cost low (~12x cheaper than Sonnet)
- NFR15: Single finalization LLM call amortizes analysis cost over entire session
- NFR16: Evidence tables separated for different access patterns (hot steering vs. cold portrait)

**Data Integrity:**
- NFR17: Hard enum for domain field ensures formula-compatible values
- NFR18: CHECK constraints on score (0-20) and confidence (0-1) fields
- NFR19: Foreign key integrity across sessions → messages → evidence chains
- NFR20: Partial unique index enforces one active session per user

**Usability:**
- NFR21: Mobile-responsive design for 30-minute sessions on smartphones
- NFR22: Touch-friendly inputs for conversational sessions
- NFR23: No form fills or questionnaire complexity — pure conversation
- NFR24: Precision meter shows message-count progress toward finalization threshold

**Maintainability:**
- NFR25: Hexagonal architecture with Effect-ts dependency injection
- NFR26: Pure domain functions (computeFacetMetrics, computeSteeringTarget) accept config as parameter
- NFR27: FORMULA_DEFAULTS frozen config object — functions never import globals
- NFR28: as-const enum pattern → TypeScript type → Effect Schema → pgEnum

**Deployment:**
- NFR29: Railway production deployment with automatic CI/CD
- NFR30: Docker multi-stage builds with health check validation
- NFR31: Drizzle migrations run automatically on backend startup
- NFR32: MOCK_LLM=true for deterministic test responses

**Accessibility:**
- NFR33: WCAG compliance for all user-facing surfaces

### Additional Requirements

**From Architecture (Two-Tier Redesign):**

1. **LangGraph Removal:** Eliminate LangGraph graph, checkpointer, PostgresSaver, cadence routing (BATCH/STEER/COAST), forkDaemon. Replace with sequential Effect.gen pipeline.
2. **New Repositories:** ConversanalyzerRepository, FinanalyzerRepository, PortraitRepository, ConversationEvidenceRepository, FinalizationEvidenceRepository, AssessmentResultRepository
3. **Database Schema Changes:**
   - New: `conversation_evidence` table (lean, steering-only, capped 3/msg)
   - New: `finalization_evidence` table (rich, portrait-quality, includes rawDomain, quote, reasoning, narrative_moves)
   - New: `assessment_results` table (JSONB facets/traits/domainCoverage + TEXT portrait + status enum)
   - Modified: `assessment_sessions` (add message_count, finalization status, drop LangGraph fields)
   - Removed: Old `facet_evidence`, `facet_scores`, `trait_scores` tables
4. **Pure Domain Functions:** `computeFacetMetrics()` and `computeSteeringTarget()` in `packages/domain/src/utils/formula.ts`
5. **EvidenceInput Type:** Minimal intersection type (`bigfiveFacet, score, confidence, domain`) used by formula functions
6. **Cold Start (msgs 1-3):** Greeting seed defaults from rotating pool of (domain, facet) pairs — no steering
7. **5-Phase Migration Sequence:** Foundation → Infrastructure → Rewire → Cleanup → Frontend+Tests (25 steps)
8. **AppConfig Changes:** MESSAGE_THRESHOLD=30 in AppConfig, not formula config
9. **API Endpoint Changes:**
   - Modified: POST /send-message (simplified — no cadence routing, returns nerin response only)
   - New: POST /generate-results (auth-required finalization trigger)
   - Modified: GET /session-status (returns active/finalizing/completed + message count)
10. **~32 files removed, ~25 added, ~20 modified** across the codebase

**From Supplemental Docs (confidence-algo.md + new-formula.md):**

11. **Facet Score Formula:** Context-level weighted mean (μ_g) with √Σc_i context weights → weighted average across domains
12. **Facet Confidence Formula:** C_f = C_max(1 - e^{-kW}) where W = Σ_g √(Σ c_i) — diversified evidence mass
13. **Signal Power Formula:** P_f = V × D (volume saturation × normalized entropy across domains)
14. **Steering Formula:** FacetPriority = α(C_target - C_f)+ + β(P_target - P_f)+, then ContextPriority with Need(f,g) + zero-evidence boost
15. **Hyperparameters:** C_max=0.9, k≈0.5-0.7, C_target=0.75, P_target=0.5, α=1.0, β=0.8, η=0.3

**From Design Thinking (design-thinking-2026-02-20.md):**

16. **Conversation-to-Portrait Transition UX:** Generation time should feel like Nerin "thinking about you" — visual shift, ocean metaphor, not a loading spinner
17. **Portrait Depth Scaling:** Evidence density drives portrait length — Rich (15+ records, 5+ contexts), Moderate (8-14), Thin (<8) → portrait prompt receives depth signal
18. **Portrait Narrative Moves Pre-Computed:** Finalization detects available moves (Deduction, Positioning, Reframing, Provocation, Prediction) before portrait generation — scaffolded not left to LLM
19. **Nerin Character Bible:** Defined personality, values, diving backstory — prerequisite for conversation engagement and natural context transitions
20. **Observation+Question Format:** Nerin's primary question format — observation proves listening, question opens new context

**From UX Design Specification:**

21. **One-Click Start:** Zero friction from landing to first Nerin message; optional sign-up after first message
22. **Streaming UI:** Nerin responses stream live without loading spinners
23. **Progress Indicator:** Message-count progress toward finalization threshold (passive feedback, not precision meter for MVP)
24. **Celebration Screen:** "Your Personality Profile is Ready!" with archetype name as emotional anchor + OCEAN code as secondary
25. **Share Flow:** One-click shareable link generation with privacy preview (shows only public archetype)
26. **Session Persistence:** User can pause at any time, resume later via session URL
27. **Dark Mode:** Full dark mode support with personality shift per visual design spec

### FR Coverage Map

| FR | Epic | Description |
|---|---|---|
| FR1 | Epic 1 | Start conversational assessment |
| FR2 | Epic 1 | Nerin conducts ~30-message dialogue |
| FR20 | Epic 1 | Sign up and log in (Better Auth) |
| FR21 | Epic 1 | Anonymous session with httpOnly cookie |
| FR22 | Epic 1 | Anonymous → authenticated transition |
| FR33 | Epic 1 | Health check endpoint |
| FR34 | Epic 1 | Effect/Platform HTTP contracts |
| FR35 | Epic 1 | Docker Compose dev environment |
| FR3 | Epic 2 | Extract Big Five facet evidence |
| FR10 | Epic 2 | Message-count progress tracking |
| FR11 | Epic 2 | Context tagging (domain + rawDomain) |
| FR12 | Epic 2 | Multi-domain evidence generation |
| FR13 | Epic 2 | Steering facet priority formula |
| FR14 | Epic 2 | Steering context priority formula |
| FR15 | Epic 2 | Steering bridge hints |
| FR16 | Epic 2 | Conversanalyzer (Haiku, every msg) |
| FR17 | Epic 2 | Conversation evidence (disposable, 3/msg cap) |
| FR23 | Epic 2 | One session per user (partial unique index) |
| FR24 | Epic 2 | Advisory lock for concurrent messages |
| FR30 | Epic 2 | Daily cost tracking ($75 limit) |
| FR31 | Epic 2 | Rate limiting (1 assessment/day) |
| FR32 | Epic 2 | Budget check per message |
| FR4 | Epic 3 | Compute facet scores |
| FR5 | Epic 3 | Compute facet confidence |
| FR5.1 | Epic 3 | Compute signal power |
| FR6 | Epic 3 | Generate OCEAN code |
| FR7 | Epic 3 | Assign archetype name |
| FR8 | Epic 3 | View private personality profile |
| FR17.1 | Epic 3 | Finanalyzer (Sonnet/Opus, once) |
| FR18 | Epic 3 | Finalization evidence as source of truth |
| FR19 | Epic 3 | Three-tier finalization idempotency |
| FR25 | Epic 3 | Session re-entry routing |
| FR26 | Epic 3 | POST /generate-results endpoint |
| FR27 | Epic 3 | Portrait generation with context-grouped evidence |
| FR28 | Epic 3 | assessment_results table |
| FR29 | Epic 3 | Pre-computed narrative moves for portrait |
| FR9 | Epic 4 | Generate shareable public archetype link |

## Epic List

### Epic 1: Start a Conversation with Nerin

Users can land on big-ocean, authenticate (or stay anonymous), start a personality assessment, and chat with Nerin — receiving streaming AI responses in a natural conversational experience. This epic delivers the core conversational loop end-to-end: auth, session creation, message exchange, and Nerin's streaming responses with cold start greeting (msgs 1-3).

**FRs covered:** FR1, FR2, FR20, FR21, FR22, FR33, FR34, FR35

### Epic 2: Conversation Intelligence

Every message gets smarter — Haiku analysis extracts facet evidence with context tags, formula-driven steering guides Nerin across life domains (work, relationships, family, leisure, solo), and cost guards protect against runaway LLM spend. The conversation becomes increasingly personalized as the system builds a breadth-first exploration of the user's whole personality.

**FRs covered:** FR3, FR10, FR11, FR12, FR13, FR14, FR15, FR16, FR17, FR23, FR24, FR30, FR31, FR32

### Epic 3: Personality Portrait & Results

After reaching the message threshold, the user triggers result generation and experiences the full reveal — finanalyzer re-analyzes all messages with complete context, scores are computed via domain-weighted formulas, an OCEAN code and archetype are assigned, and a narrative portrait is generated from context-grouped evidence with pre-computed narrative moves. The results page delivers the celebration moment with the archetype name as emotional anchor, trait breakdowns, and the full portrait reading experience. Includes the conversation-to-portrait transition UX, session re-entry routing, and three-tier finalization idempotency.

**FRs covered:** FR4, FR5, FR5.1, FR6, FR7, FR8, FR17.1, FR18, FR19, FR25, FR26, FR27, FR28, FR29

### Epic 4: Sharing & Public Profile

Users can generate a shareable link that shows their OCEAN code and archetype to friends — creating a social discovery moment while keeping their full profile private. Includes one-click link generation, public archetype view, privacy preview, and link recipient experience.

**FRs covered:** FR9

---

## Epic 1: Start a Conversation with Nerin

Users can land on big-ocean, authenticate (or stay anonymous), start a personality assessment, and chat with Nerin — receiving streaming AI responses in a natural conversational experience. This epic delivers the core conversational loop end-to-end: auth, session creation, message exchange, and Nerin's streaming responses with cold start greeting (msgs 1-3).

### Story 1.1: Anonymous Assessment Start

As a visitor,
I want to start a personality assessment without signing up,
So that I experience Nerin immediately with zero friction.

**Acceptance Criteria:**

**Given** a visitor lands on the assessment page
**When** they click "Start"
**Then** an anonymous session is created with a httpOnly cookie
**And** the `assessment_sessions` table stores the session with `user_id = NULL`
**And** the visitor is taken to the chat interface

**Given** an anonymous session exists
**When** the visitor returns later with the same cookie
**Then** their existing session is resumed

### Story 1.2: Send Message & Nerin Response

As a user (anonymous or authenticated),
I want to send messages to Nerin and receive streaming responses,
So that I have a natural conversational experience.

**Acceptance Criteria:**

**Given** a user has an active assessment session
**When** they type a message and press send
**Then** the message is stored in `assessment_messages` and POST /send-message is called
**And** Nerin's response streams back in real-time (< 2 second perceived latency)
**And** the response is stored as an assistant message in `assessment_messages`

**Given** a user sends their first message
**When** Nerin responds
**Then** Nerin uses cold start greeting seed (rotating domain/facet pairs for msgs 1-3)
**And** no steering or analysis runs for the first 3 messages

**Given** a user sends a message
**When** the streaming response is in progress
**Then** a typing indicator shows Nerin is responding
**And** the message input is disabled until Nerin finishes

### Story 1.3: User Registration & Login

As a visitor,
I want to sign up with email and password or log in to an existing account,
So that my assessment is saved to my account and I can access it later.

**Acceptance Criteria:**

**Given** a visitor wants to create an account
**When** they submit registration with email and password (12+ chars)
**Then** a user account is created via Better Auth
**And** compromised credential checks are performed
**And** the user is logged in automatically

**Given** a registered user
**When** they log in with valid credentials
**Then** they are authenticated and redirected to their session

**Given** invalid credentials
**When** a user attempts to log in
**Then** a clear error message is displayed without revealing which field is wrong

### Story 1.4: Anonymous-to-Authenticated Transition

As an anonymous user who has been chatting with Nerin,
I want to sign up and have my existing session linked to my new account,
So that I don't lose my conversation progress.

**Acceptance Criteria:**

**Given** an anonymous user with an active session
**When** they sign up or log in
**Then** the existing session's `user_id` is updated to the new account
**And** the httpOnly cookie token is rotated
**And** the conversation continues seamlessly

**Given** an authenticated user
**When** a partial unique index check runs
**Then** only one active session per `user_id` is allowed (`WHERE user_id IS NOT NULL`)

### Story 1.5: Chat Interface & Conversation UX

As a user,
I want a clean, mobile-responsive chat interface,
So that chatting with Nerin feels natural like a messaging app.

**Acceptance Criteria:**

**Given** a user is on the chat page
**When** the page loads
**Then** the chat interface displays previous messages (if resuming)
**And** the message input is focused and ready for typing
**And** the interface is mobile-responsive and touch-friendly

**Given** a user is chatting
**When** messages are exchanged
**Then** messages appear in chronological order with clear user/Nerin distinction
**And** the view auto-scrolls to the latest message
**And** the interface supports 30+ messages without performance degradation

---

## Epic 2: Conversation Intelligence

Every message gets smarter — Haiku analysis extracts facet evidence with context tags, formula-driven steering guides Nerin across life domains (work, relationships, family, leisure, solo), and cost guards protect against runaway LLM spend. The conversation becomes increasingly personalized as the system builds a breadth-first exploration of the user's whole personality.

### Story 2.1: Conversation Evidence Schema & Repository

As a developer,
I want the conversation_evidence table and repository to exist,
So that the conversanalyzer can persist extracted evidence for steering.

**Acceptance Criteria:**

**Given** the database schema
**When** migrations run
**Then** `conversation_evidence` table exists with columns: id (UUID PK), assessment_session_id (FK), assessment_message_id (FK), bigfive_facet (pgEnum), score (SMALLINT 0-20), confidence (NUMERIC 0-1), domain (pgEnum: work/relationships/family/leisure/solo/other), created_at
**And** CHECK constraints enforce score 0-20 and confidence 0-1
**And** pgEnums `bigfive_facet_name` and `evidence_domain` are created using as-const → Schema → pgEnum pattern

**Given** a ConversationEvidenceRepository interface (Context.Tag)
**When** implemented as ConversationEvidenceDrizzleRepositoryLive
**Then** it supports: `save(records[])`, `findBySession(sessionId)`, `countByMessage(messageId)`
**And** save enforces 3 records per message cap

### Story 2.2: Conversanalyzer — Haiku Analysis on Every Message

As a system,
I want to analyze every user message with Haiku to extract facet evidence with domain tags,
So that steering has fresh data after every message.

**Acceptance Criteria:**

**Given** a user sends a message (after cold start, msg 4+)
**When** the send-message pipeline runs
**Then** Haiku analyzes the message synchronously (< 1 second)
**And** extracts 1-3 evidence records with: bigfive_facet, score (0-20), confidence (0-1), domain, rawDomain
**And** evidence is saved to `conversation_evidence`

**Given** a message that spans multiple life domains
**When** Haiku analyzes it
**Then** separate evidence records are generated with the same quote but different domain/rawDomain tags

**Given** the ConversanalyzerRepository interface (Context.Tag)
**When** implemented as ConversanalyzerAnthropicRepositoryLive
**Then** it calls Haiku with the current message + recent conversation context
**And** returns structured evidence matching the EvidenceInput type

### Story 2.3: Formula Functions — Facet Metrics & Steering Target

As a developer,
I want pure domain functions that compute facet metrics and steering targets from evidence,
So that steering is deterministic, testable, and zero-LLM-cost.

**Acceptance Criteria:**

**Given** a set of conversation evidence records
**When** `computeFacetMetrics(evidence, config)` is called
**Then** it returns per-facet: score (context-weighted mean), confidence (C_max(1 - e^{-kW})), signalPower (V × D)
**And** context weights use √Σc_i per domain (anti-redundancy)
**And** signal power uses normalized entropy across domains

**Given** facet metrics
**When** `computeSteeringTarget(metrics, config)` is called
**Then** it returns the target facet (highest FacetPriority = α(C_target - C_f)+ + β(P_target - P_f)+)
**And** the target context (highest ContextPriority = Need(f,g) + η·1(w=0))
**And** a natural language steering hint

**Given** FORMULA_DEFAULTS config
**When** functions are called
**Then** they accept config as parameter (never import globals)
**And** FORMULA_DEFAULTS is Object.freeze'd with: C_max=0.9, k=0.7, C_target=0.75, P_target=0.5, α=1.0, β=0.8, η=0.3

**Given** these are pure functions in `packages/domain/src/utils/formula.ts`
**When** unit tested
**Then** 100% branch coverage with deterministic inputs/outputs

### Story 2.4: Steering Integration — Smart Nerin Responses

As a user,
I want Nerin to naturally explore different areas of my life as we chat,
So that the conversation covers my whole personality, not just one topic.

**Acceptance Criteria:**

**Given** a user sends message 4+ (post cold start)
**When** the send-message pipeline runs
**Then** the flow is: Haiku analyze → compute steering → pass hint to Nerin → Nerin responds
**And** the steering hint includes a target facet, target context, and conversational bridge
**And** the bridge references something the user already said

**Given** steering detects zero evidence from a domain (e.g., family)
**When** computing context priority
**Then** that domain gets η=0.3 zero-evidence boost
**And** steering naturally guides Nerin toward that unexplored domain

**Given** the send-message use-case
**When** refactored from LangGraph orchestration
**Then** it uses a sequential Effect.gen pipeline (no graph, no checkpointer, no cadence routing)
**And** every message follows the same flow (no BATCH/STEER/COAST distinction)

### Story 2.5: Message-Count Progress & Session Guards

As a user,
I want to see how far along I am in my conversation,
So that I know when my portrait will be ready.

**Acceptance Criteria:**

**Given** a user is chatting
**When** they send a message
**Then** the session's `message_count` is incremented
**And** the frontend displays message-count progress toward MESSAGE_THRESHOLD (30)

**Given** a user sends a message on a session
**When** another request arrives concurrently for the same session
**Then** `pg_try_advisory_lock(session_id)` prevents race conditions
**And** the second request receives an appropriate error

**Given** MESSAGE_THRESHOLD is configured in AppConfig
**When** message_count reaches the threshold
**Then** the frontend enables the "Generate Results" button
**And** Nerin's responses begin winding down the conversation naturally

### Story 2.6: Cost Tracking & Rate Limiting

As the system,
I want to enforce daily cost budgets and assessment rate limits,
So that LLM costs are controlled and fair access is maintained.

**Acceptance Criteria:**

**Given** a user sends a message
**When** the budget check runs
**Then** `dailyCostUsed + estimatedMessageCost` is checked against the $75 daily limit
**And** if exceeded, a BudgetPausedError is thrown with `resumeAfter` = next day midnight UTC

**Given** a user tries to start a new assessment
**When** `canStartAssessment(userId)` is checked
**Then** only 1 new assessment per user per day is allowed
**And** if exceeded, RateLimitExceeded is thrown with `resetAt` = next day midnight UTC
**And** anonymous users bypass rate limiting

**Given** Redis cost tracking
**When** cost is incremented
**Then** atomic INCRBY operations are used with key pattern `cost:{userId}:{YYYY-MM-DD}`
**And** keys have 48-hour TTL for automatic daily reset

**Given** any cost event
**When** it occurs
**Then** structured Pino logging captures: userId, costCents, dailyTotal, dateKey

---

## Epic 3: Personality Portrait & Results

After reaching the message threshold, the user triggers result generation and experiences the full reveal — finanalyzer re-analyzes all messages with complete context, scores are computed via domain-weighted formulas, an OCEAN code and archetype are assigned, and a narrative portrait is generated from context-grouped evidence with pre-computed narrative moves. The results page delivers the celebration moment with the archetype name as emotional anchor, trait breakdowns, and the full portrait reading experience.

### Story 3.1: Finalization Evidence Schema & Repository

As a developer,
I want the finalization_evidence table and repository to exist,
So that the finanalyzer can persist rich, portrait-quality evidence.

**Acceptance Criteria:**

**Given** the database schema
**When** migrations run
**Then** `finalization_evidence` table exists with columns: id (UUID PK), assessment_session_id (FK), assessment_message_id (FK), bigfive_facet (pgEnum), score (SMALLINT 0-20), confidence (NUMERIC 0-1), domain (pgEnum), rawDomain (TEXT), quote (TEXT), reasoning (TEXT), narrative_moves (TEXT[]), created_at
**And** CHECK constraints enforce score 0-20 and confidence 0-1

**Given** a FinalizationEvidenceRepository interface (Context.Tag)
**When** implemented as FinalizationEvidenceDrizzleRepositoryLive
**Then** it supports: `save(records[])`, `findBySession(sessionId)`, `existsBySession(sessionId)`

### Story 3.2: Assessment Results Schema & Repository

As a developer,
I want the assessment_results table and repository to exist,
So that computed scores, OCEAN code, archetype, and portrait can be persisted.

**Acceptance Criteria:**

**Given** the database schema
**When** migrations run
**Then** `assessment_results` table exists with columns: id (UUID PK), assessment_session_id (FK UNIQUE), facets (JSONB), traits (JSONB), domain_coverage (JSONB), ocean_code (VARCHAR(5)), archetype_name (TEXT), portrait (TEXT), status (pgEnum: pending/generating/completed/failed), created_at, completed_at
**And** status enum follows as-const → Schema → pgEnum pattern

**Given** an AssessmentResultRepository interface (Context.Tag)
**When** implemented as AssessmentResultDrizzleRepositoryLive
**Then** it supports: `create(sessionId)`, `findBySession(sessionId)`, `updateWithResults(id, results)`, `updateStatus(id, status)`

### Story 3.3: Finanalyzer — Full Re-Analysis at Finalization

As a system,
I want to re-analyze ALL conversation messages with Sonnet/Opus at finalization,
So that evidence is maximally accurate with complete conversation context.

**Acceptance Criteria:**

**Given** finalization is triggered for a session
**When** the finanalyzer runs
**Then** ALL messages are sent to Sonnet/Opus in a single batch call
**And** evidence records include: bigfive_facet, score, confidence, domain, rawDomain, quote, reasoning, narrative_moves
**And** narrative_moves are pre-computed per evidence (Deduction, Positioning, Reframing, Provocation, Prediction)
**And** results are saved to `finalization_evidence`

**Given** a FinanalyzerRepository interface (Context.Tag)
**When** implemented as FinanalyzerAnthropicRepositoryLive
**Then** it processes the complete conversation with full context
**And** early conversation-time domain tags may be corrected with full context

**Given** finalization evidence already exists for a session
**When** finanalyzer is called again
**Then** it short-circuits (idempotency tier 2) and returns existing evidence

### Story 3.4: Score Computation & OCEAN Code Generation

As a system,
I want to compute final facet/trait scores and generate the OCEAN code from finalization evidence,
So that the user's personality profile is scientifically grounded.

**Acceptance Criteria:**

**Given** finalization evidence for a session
**When** score computation runs
**Then** `computeFacetMetrics()` produces per-facet: score, confidence, signalPower using finalization evidence
**And** trait scores are aggregated from their 6 constituent facets (weighted mean)
**And** domain coverage is computed (evidence count per domain)

**Given** computed trait scores
**When** OCEAN code generation runs
**Then** `generateOceanCode()` maps 5 trait scores to a 5-letter code (L/M/H per trait)
**And** thresholds: 0-40=L, 40-80=M, 80-120=H (sum of 6 facets per trait, each 0-20)

**Given** computed scores and OCEAN code
**When** archetype assignment runs
**Then** an archetype name is assigned based on the OCEAN code and trait analysis
**And** all results are saved to `assessment_results` via `updateWithResults()`

### Story 3.5: Portrait Generation

As a system,
I want to generate a narrative personality portrait from context-grouped evidence,
So that the user receives a deeply personal, surprising portrait experience.

**Acceptance Criteria:**

**Given** finalization evidence exists for a session
**When** portrait generation runs
**Then** evidence is grouped by domain (work, relationships, family, leisure, solo, other)
**And** available narrative moves are aggregated from evidence records
**And** a depth signal is computed: Rich (15+ records, 5+ contexts), Moderate (8-14, 3-4), Thin (<8, 1-2)
**And** the portrait LLM (Opus) receives: context-grouped evidence, available moves, depth signal, facet/trait scores

**Given** a PortraitRepository interface (Context.Tag)
**When** implemented as PortraitAnthropicRepositoryLive
**Then** it generates a narrative portrait as TEXT
**And** the portrait is saved to `assessment_results.portrait`
**And** status is updated to `completed`

**Given** portrait generation fails
**When** an error occurs
**Then** status is updated to `failed`
**And** the error is logged with structured Pino logging

### Story 3.6: Generate Results Endpoint & Finalization Pipeline

As an authenticated user,
I want to trigger result generation when my conversation reaches the threshold,
So that I receive my complete personality portrait.

**Acceptance Criteria:**

**Given** an authenticated user with message_count >= MESSAGE_THRESHOLD
**When** they click "Generate My Results" (POST /generate-results)
**Then** the finalization pipeline runs: finanalyzer → score computation → OCEAN code → archetype → portrait
**And** session status transitions: active → finalizing → completed
**And** the user sees the conversation-to-portrait transition (Nerin "thinking about you" visual, not a loading spinner)

**Given** an anonymous user
**When** they try to trigger finalization
**Then** they are prompted to sign up first (auth-required endpoint)

**Given** three-tier finalization idempotency
**When** generate-results is called
**Then** Tier 1: if `assessment_results` exists with status=completed, return existing results
**And** Tier 2: if `finalization_evidence` exists, skip finanalyzer, run scoring + portrait only
**And** Tier 3: full pipeline (finanalyzer → scoring → portrait)

### Story 3.7: Results Page & Profile Viewing

As a user,
I want to view my complete personality profile after generation,
So that I experience the celebration reveal with my archetype, OCEAN code, traits, and portrait.

**Acceptance Criteria:**

**Given** results are completed for a session
**When** the user navigates to the results page
**Then** the celebration screen displays "Your Personality Profile is Ready!"
**And** the archetype name is the emotional anchor (h1, display scale)
**And** the OCEAN code is displayed as strong secondary (monochrome, typographic)
**And** trait breakdowns show per-trait scores with visual indicators
**And** the full narrative portrait is displayed as a reading experience

**Given** session re-entry routing
**When** a user returns to the app
**Then** GET /session-status returns active/finalizing/completed
**And** if active: route to chat interface
**And** if finalizing: route to transition/waiting screen
**And** if completed: route to results page

**Given** the results page
**When** viewed on mobile
**Then** the layout is responsive and the portrait reading experience is optimized for scrolling

---

## Epic 4: Sharing & Public Profile

Users can generate a shareable link that shows their OCEAN code and archetype to friends — creating a social discovery moment while keeping their full profile private.

### Story 4.1: Shareable Link Generation

As a user who has their results,
I want to generate a shareable link with one click,
So that I can share my personality archetype with friends.

**Acceptance Criteria:**

**Given** a user is viewing their results
**When** they click "Share My Archetype"
**Then** a unique shareable link is generated (e.g., /profile/{shareToken})
**And** the link is copyable to clipboard
**And** social sharing options are available (copy link, share to platforms)

**Given** a user wants to preview what's shared
**When** they view the share preview
**Then** they see exactly what the recipient will see: OCEAN code + archetype name + essence
**And** private profile details (full portrait, trait breakdowns) are NOT included
**And** the user feels confident about what's being shared

### Story 4.2: Public Archetype View

As a link recipient,
I want to see a friend's OCEAN code and archetype when I click their shared link,
So that I can discover their personality type and compare with mine.

**Acceptance Criteria:**

**Given** a recipient clicks a shared link
**When** the public archetype page loads
**Then** the OCEAN code and archetype name are displayed prominently
**And** a brief archetype essence/description is shown
**And** NO private profile data, portrait text, or detailed scores are visible

**Given** a recipient views the public profile
**When** they want to discover their own type
**Then** a clear CTA invites them to "Discover Your Type" (start their own assessment)
**And** this creates the viral loop: see friend's code → want to know mine

**Given** an invalid or expired share token
**When** the link is accessed
**Then** a friendly error page is shown with an option to start their own assessment
